name: Deploy to VPS

on:
  workflow_run:
    workflows:
      - CI - Code Quality & Tests
    types:
      - completed
  workflow_dispatch:

concurrency:
  group: vps-master
  cancel-in-progress: false

jobs:
  deploy:
    runs-on: ubuntu-latest
    if: >
      github.event_name == 'workflow_dispatch' ||
      (
        github.event_name == 'workflow_run' &&
        github.event.workflow_run.conclusion == 'success' &&
        github.event.workflow_run.head_branch == 'master'
      )
    permissions:
      contents: read
      actions: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: "recursive"

      - name: Prepare SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.VPS_SSH_KEY }}

      - name: Add VPS to known hosts
        env:
          VPS_PORT: ${{ secrets.VPS_PORT }}
        run: |
          mkdir -p ~/.ssh
          VPS_PORT="${VPS_PORT:-22}"
          ssh-keyscan -p "${VPS_PORT}" -H "${{ secrets.VPS_HOST }}" >> ~/.ssh/known_hosts

      - name: Set branch and commit
        id: ref
        run: |
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            echo "BRANCH=${{ github.event.workflow_run.head_branch }}" >>$GITHUB_ENV
            echo "COMMIT_SHA=${{ github.event.workflow_run.head_sha }}" >>$GITHUB_ENV
          else
            echo "BRANCH=${GITHUB_REF_NAME}" >>$GITHUB_ENV
            echo "COMMIT_SHA=${{ github.sha }}" >>$GITHUB_ENV
          fi

      - name: Wait for CI success
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 - <<'PY'
          import json
          import os
          import sys
          import time
          import urllib.request
          
          repo = os.environ["GITHUB_REPOSITORY"]
          sha = os.environ.get("COMMIT_SHA") or os.environ["GITHUB_SHA"]
          token = os.environ.get("GITHUB_TOKEN")
          event_name = os.environ.get("GITHUB_EVENT_NAME", "")
          workflow_name = os.environ.get("CI_WORKFLOW_NAME", "CI - Code Quality & Tests")
          workflow_file = os.environ.get("CI_WORKFLOW_FILE", "ci.yml")
          max_attempts = 30
          sleep_seconds = 20
          
          base_headers = {
              "Authorization": f"Bearer {token}",
              "Accept": "application/vnd.github+json",
          }
          
          workflows_url = f"https://api.github.com/repos/{repo}/actions/workflows"
          workflows_req = urllib.request.Request(workflows_url, headers=base_headers)
          workflow_id = None
          with urllib.request.urlopen(workflows_req, timeout=20) as resp:
              data = json.loads(resp.read().decode("utf-8"))
          for wf in data.get("workflows", []):
              if wf.get("name") == workflow_name:
                  workflow_id = wf.get("id")
                  break
          workflow_ref = workflow_id or workflow_file
          
          url = f"https://api.github.com/repos/{repo}/actions/workflows/{workflow_ref}/runs?head_sha={sha}&per_page=1"
          req = urllib.request.Request(url, headers=base_headers)
          
          for attempt in range(1, max_attempts + 1):
              with urllib.request.urlopen(req, timeout=20) as resp:
                  data = json.loads(resp.read().decode("utf-8"))
          
              runs = data.get("workflow_runs", [])
              if not runs:
                  if event_name == "workflow_dispatch":
                      print("No CI runs found for this commit yet (manual deploy). Skipping wait.")
                      sys.exit(0)
                  print("No CI runs found for this commit yet.")
              else:
                  run = runs[0]
                  status = run.get("status")
                  conclusion = run.get("conclusion")
                  print(f"CI status={status}, conclusion={conclusion}")
                  if status == "completed":
                      if conclusion != "success":
                          print(f"CI run conclusion is {conclusion}. Aborting deploy.")
                          sys.exit(1)
                      print("CI succeeded, proceeding with deploy.")
                      sys.exit(0)
          
              if attempt < max_attempts:
                  time.sleep(sleep_seconds)
          
          print("CI did not complete in time. Aborting deploy.")
          sys.exit(1)
          PY

      - name: Deploy via SSH
        env:
          VPS_PORT: ${{ secrets.VPS_PORT }}
          VPS_PATH: ${{ secrets.VPS_PATH }}
        run: |
          BRANCH="${BRANCH:-master}"
          COMMIT_SHA="${COMMIT_SHA:-$(git rev-parse HEAD)}"
          VPS_PORT="${VPS_PORT:-22}"
          ssh -p "${VPS_PORT}" \
            "${{ secrets.VPS_USER }}"@"${{ secrets.VPS_HOST }}" \
            VPS_PATH="${VPS_PATH}" \
            BRANCH="${BRANCH}" \
            COMMIT_SHA="${COMMIT_SHA}" \
            bash -s <<'EOF'
          set -Eeuo pipefail

          on_error() {
            rc=$?
            # Avoid leaking secrets: print only the command name (first word), not args.
            cmd="${BASH_COMMAND%% *}"
            echo "ERROR: rc=${rc} line=${1} cmd=${cmd}"
            exit "${rc}"
          }
          trap 'on_error ${LINENO}' ERR

          echo "MARK: start"
          echo "MARK: VPS_PATH=${VPS_PATH} BRANCH=${BRANCH} COMMIT_SHA=${COMMIT_SHA}"
          trap 'rc=$?; echo "MARK: exit rc=${rc}"' EXIT

          cd "${VPS_PATH}"
          echo "MARK: cd ok, pwd=$(pwd)"

          echo "Fetching ${BRANCH}..."
          git fetch origin "${BRANCH}" --quiet

          # Ensure checkout cannot be blocked by local edits to tracked files
          # (untracked files like .env.production must remain untouched).
          git reset --hard --quiet
          git checkout "${COMMIT_SHA}"
          git submodule sync --recursive
          git submodule update --init --recursive

          if [ ! -f .env.production ]; then
            echo "Missing .env.production on server. Configure secrets via SSH before deploy."
            exit 1
          fi

          echo "MARK: env-file info"
          echo "MARK: env-file sha256=$(sha256sum .env.production | awk '{print $1}')"
          echo "MARK: env-file keys (masked):"
          grep -E '^(IMAGE_TAG|MAILCOW_)=' .env.production 2>/dev/null | sed -E 's/=(.*)$/=***/' || true

          echo "MARK: before app compose up"
          echo "Building and restarting stack"
          # Tag images by commit so frontend changes always produce a new image.
          export IMAGE_TAG="${COMMIT_SHA}"
          echo "Deploy vars: BRANCH=${BRANCH} COMMIT_SHA=${COMMIT_SHA} IMAGE_TAG=${IMAGE_TAG}"
          docker compose -f docker-compose.prod.yml --env-file .env.production up --pull=never --build -d --force-recreate backend telegram_bot frontend nginx

          echo "MARK: after app compose up"
          echo "Running containers:"
          docker compose -f docker-compose.prod.yml --env-file .env.production ps

          echo "Resolved images:"
          docker compose -f docker-compose.prod.yml --env-file .env.production config | awk '/^[[:space:]]*image:/{print $0}'

          echo "Frontend assets fingerprint:"
          # Show the asset filenames that prove the frontend bundle changed.
          docker exec crm3-frontend sh -lc 'ls -1 /usr/share/nginx/html/assets 2>/dev/null | head -n 20 || true'
          docker exec crm3-frontend sh -lc 'head -n 25 /usr/share/nginx/html/index.html 2>/dev/null || true'

          echo "Pruning unused images"
          docker image prune -f

          echo "MARK: end"
          EOF
